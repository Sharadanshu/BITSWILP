{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd14fc5",
   "metadata": {
    "id": "5cd14fc5"
   },
   "source": [
    "## Mini Chess Solver Using Dynamic Programming - Total 7 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49524177",
   "metadata": {
    "id": "49524177"
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "Design and implement a reinforcement learning agent using dynamic programming (value iteration or policy iteration) to compute an optimal policy for a simplified chess game. The agent plays as White and must learn how to convert an advantage into a win or at least avoid a loss in a MiniChess game against a defensive opponent. The problem must be modelled as a finite MDP. Register number of first student in a group (alphabetically sorted) will be considered for configuration design.\n",
    "The student will:\n",
    "* Implement a custom Mini Chess environment.\n",
    "* Use dynamic programming to compute the optimal value function and policy.\n",
    "* Analyze how state design and reward shaping affect the learned policy and convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d3b7",
   "metadata": {
    "id": "f2a8d3b7"
   },
   "source": [
    "### Scenario\n",
    "\n",
    "You are building a “Mini Chess Game” for beginner players. The coach focuses on a small, tractable game:\n",
    "* White: King + Pawn\n",
    "* Black: King\n",
    "* Board: 4×4 or 5×5 MiniChess board\n",
    "* White moves first and tries to either:\n",
    "    * Promote the pawn and then deliver checkmate, or\n",
    "    * Force a checkmate directly (if possible)\n",
    "\n",
    "Black tries to prevent this by blocking the pawn, chasing the white king, or capturing the pawn. The game is restricted to this small set of pieces and a tiny board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf39bfe",
   "metadata": {
    "id": "fbf39bfe"
   },
   "source": [
    "### Environment Description\n",
    "#### Board and Pieces\n",
    "* Board size:\n",
    "    * If the student roll number / registration number is even: use a 4×4 board (rows 0–3, cols 0–3).\n",
    "    * If odd: use a 5×5 board (rows 0–4, cols 0–4).\n",
    "* Pieces always present:\n",
    "    * White King (WK)\n",
    "    * White Pawn (WP)\n",
    "    * Black King (BK)\n",
    "    * No castling, no en passant, no promotion to anything other than Queen.\n",
    "* Legal Moves\n",
    "    * Kings move like normal chess kings - one square in any direction (8- neighborhood), staying on the board.\n",
    "    * Pawn:\n",
    "        * Moves one square forward (towards larger row index or smaller row index – the student must choose and clearly document a convention).\n",
    "        * Captures diagonally forward by one square.\n",
    "    * All usual constraints apply:\n",
    "        * Kings cannot move into check.\n",
    "        * Two kings may never occupy adjacent squares (illegal state).\n",
    "        * A piece cannot move through other pieces.\n",
    "* Episode Termination\n",
    "    * An episode ends when any of the following happens:\n",
    "        * Checkmate (White checkmates Black).\n",
    "        * Stalemate (side to move has no legal moves but is not in check).\n",
    "        * Pawn Capture (Black captures the White pawn).\n",
    "        * Pawn Promotion (White pawn reaches last rank and becomes a Queen). After promotion, they may either:\n",
    "                * (a) terminate immediately with a reward, or\n",
    "                * (b) continue playing with a Queen replacing the pawn.\n",
    "        * The student must choose one approach and justify it.\n",
    "        * Move limit exceeded (e.g., 20 or 30 plies) – draw\n",
    "1. State Space\n",
    "\n",
    "* Each state should minimally encode:\n",
    "    * Coordinates of WK: (r_wk, c_wk)\n",
    "    * Coordinates of WP (or a special value if promoted/captured): (r_wp, c_wp) or status flag\n",
    "    * Coordinates of BK: (r_bk, c_bk)\n",
    "    * Player to move: {White, Black}\n",
    "    * Any additional flags that can be necessary like,\n",
    "        * Has the pawn promoted?\n",
    "        * Check / checkmate / stalemate indicators.\n",
    "* The student must:\n",
    "    * Describe the state representation clearly.\n",
    "2. Action Space\n",
    "    * For each state, actions are the legal moves for the side to move:\n",
    "        * Move King to a legal square\n",
    "        * Move Pawn / promoted Queen\n",
    "    * The student must implement a function that, given a state, returns all legal actions.\n",
    "3. Rewards\n",
    "* The student has to define the reward schemes like:\n",
    "    * White checkmates Black: +10\n",
    "    * Pawn gets captured: -10\n",
    "    * Stalemate or draw by move limit: 0\n",
    "    * All non-terminal moves: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10018a",
   "metadata": {
    "id": "6c10018a"
   },
   "source": [
    "**Team Members:**\n",
    "- 2024AD05008 - SHARADANSHU RAJ (100%)\n",
    "- 2024AC05922 - NISHIT UPAL (100%)\n",
    "- 2024AC05923 - NILESH DHAWAL (100%)\n",
    "- 2024ad05002 - SuryaDharshini S (100%)\n",
    "- 2024ac05246 - Suggula Naga Sai Teja (100%))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78485d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install numpy pandas matplotlib math itertools time listings typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddea2384",
   "metadata": {
    "id": "ddea2384"
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from collections import deque, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional, Iterable, Any\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab2df65",
   "metadata": {
    "id": "fab2df65"
   },
   "outputs": [],
   "source": [
    "# Basic types and helpers\n",
    "\n",
    "Pos = Tuple[int, int] # (row, col)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class State:\n",
    "    # define wk,wp,bk and the other things needed\n",
    "    wk: Pos\n",
    "    wp: Optional[Pos] # None if captured or promoted\n",
    "    bk: Pos\n",
    "    to_move: str # 'W' or 'B'\n",
    "    promoted: bool = False\n",
    "\n",
    "    def as_tuple(self):\n",
    "        return (self.wk, self.wp, self.bk, self.to_move, self.promoted)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Action:\n",
    "    piece: str # 'K' or 'P' or 'Q' (after promotion)\n",
    "    src: Pos\n",
    "    dst: Pos\n",
    "\n",
    "    def as_tuple(self):\n",
    "        return (self.piece, self.src, self.dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230aa266",
   "metadata": {},
   "source": [
    "## MDP specification: state, action, reward, terminal\n",
    "\n",
    "- **State representation**: each state is represented by the tuple `(wk, wp, bk, to_move, promoted)` where `wk`, `wp`, `bk` are (row, col) coordinates or `None` (for `wp` if captured), `to_move` ∈ {`'W'`,`'B'`}, and `promoted` is a boolean flag. This compact tuple is implemented by the `State` dataclass and used as the canonical state key.\n",
    "\n",
    "- **Action space**: for the active player the actions are all legal moves for their pieces:\n",
    "  - `K` (king) moves: one-step in 8 directions, constrained by board and adjacency rules.\n",
    "  - `P` (pawn) moves: forward one-square (if empty) and diagonal captures (if opponent occupies capture square).\n",
    "  - After promotion (not modeled as continuing play here) a `Q` action would be required; this notebook terminates on promotion to keep analysis focused.\n",
    "\n",
    "- **Reward function**:\n",
    "  - White checkmates Black: `+10`.\n",
    "  - Pawn gets captured by Black: `-10`.\n",
    "  - Pawn promotion (modeled as immediate success): `+10`.\n",
    "  - Stalemate / move-limit draw: `0`.\n",
    "  - Non-terminal moves: `0`.\n",
    "\n",
    "- **Terminal states**:\n",
    "  - Any state flagged as `done=True` in `transitions()` (promotion, pawn capture, checkmate, stalemate, or draw by move limit). The DP algorithms treat these outcomes as terminal rewards in backups.\n",
    "\n",
    "(These definitions are enforced and used by the `legal_actions`, `_apply_action_once`, and `transitions` functions.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ff83072",
   "metadata": {
    "id": "2ff83072"
   },
   "outputs": [],
   "source": [
    "# Define the MiniChess Environment - 1.5 mark\n",
    "class MiniChessEnv:\n",
    "    def __init__(self, board_size: int = 4, pawn_dir: int = -1, max_steps: int = 50):\n",
    "        \"\"\"\n",
    "        board_size: 4 or 5\n",
    "        pawn_dir: -1 means white pawn moves to decreasing row index (upwards)\n",
    "        \"\"\"\n",
    "        self.N = board_size\n",
    "        self.pawn_dir = pawn_dir\n",
    "        self.max_steps = max_steps\n",
    "        self.reset()\n",
    "\n",
    "    # Define functions for board & positions\n",
    "    def on_board(self, pos):\n",
    "        r, c = pos\n",
    "        return 0 <= r < self.N and 0 <= c < self.N\n",
    "\n",
    "    def king_moves(self, pos):\n",
    "        r, c = pos\n",
    "        for dr in (-1, 0, 1):\n",
    "            for dc in (-1, 0, 1):\n",
    "                if dr == 0 and dc == 0:\n",
    "                    continue\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if self.on_board((nr, nc)):\n",
    "                    yield (nr, nc)\n",
    "\n",
    "    def pawn_forward(self, pos):\n",
    "        r, c = pos\n",
    "        return (r + self.pawn_dir, c)\n",
    "\n",
    "    def pawn_attack_squares(self, pos):\n",
    "        r, c = pos\n",
    "        for dc in (-1, 1):\n",
    "            nr, nc = r + self.pawn_dir, c + dc\n",
    "            if self.on_board((nr, nc)):\n",
    "                yield (nr, nc)\n",
    "\n",
    "    # Define functions for game rules and legality checks\n",
    "    def kings_adjacent(self, wk, bk):\n",
    "        return max(abs(wk[0] - bk[0]), abs(wk[1] - bk[1])) <= 1\n",
    "\n",
    "    def is_attacked_by_white(self, square, state):\n",
    "        # Attacked by white king\n",
    "        if max(abs(square[0] - state.wk[0]), abs(square[1] - state.wk[1])) == 1:\n",
    "            return True\n",
    "        # Attacked by pawn (pawn captures diagonally)\n",
    "        if state.wp is not None and not state.promoted:\n",
    "            for s in self.pawn_attack_squares(state.wp):\n",
    "                if s == square:\n",
    "                    return True\n",
    "        # We do not implement full queen attacks because we terminate on promotion\n",
    "        return False\n",
    "\n",
    "    def in_check(self, state, color):\n",
    "        # color is 'W' or 'B' representing side to check\n",
    "        if color == 'B':\n",
    "            # is black king attacked by white?\n",
    "            return self.is_attacked_by_white(state.bk, state)\n",
    "        else:\n",
    "            # white can only be attacked by black king (adjacent) in this simplified game\n",
    "            return max(abs(state.wk[0] - state.bk[0]), abs(state.wk[1] - state.bk[1])) == 1\n",
    "\n",
    "    def legal_actions(self, state: State) -> List[Action]:\n",
    "        \"\"\"Return a list of legal Action objects for the side to move in the given state.\n",
    "        We enforce:\n",
    "          - kings not adjacent\n",
    "          - not moving onto own piece\n",
    "          - kings cannot move into squares attacked by opponent\n",
    "          - pawn moves/captures obey simple rules\n",
    "        \"\"\"\n",
    "        actions: List[Action] = []\n",
    "        if state.to_move == 'W':\n",
    "            # White king moves\n",
    "            for dst in self.king_moves(state.wk):\n",
    "                # cannot move onto own pawn\n",
    "                if state.wp is not None and dst == state.wp:\n",
    "                    continue\n",
    "                # cannot move onto black king\n",
    "                if dst == state.bk:\n",
    "                    continue\n",
    "                # kings cannot be adjacent\n",
    "                if self.kings_adjacent(dst, state.bk):\n",
    "                    continue\n",
    "                # cannot move into check (square attacked by black)\n",
    "                # black only attacks adjacent squares with king\n",
    "                if max(abs(dst[0] - state.bk[0]), abs(dst[1] - state.bk[1])) == 1:\n",
    "                    continue\n",
    "                actions.append(Action('K', state.wk, dst))\n",
    "\n",
    "            # Pawn moves\n",
    "            if state.wp is not None and not state.promoted:\n",
    "                fwd = self.pawn_forward(state.wp)\n",
    "                # forward one if empty and on board\n",
    "                occupied = {state.wk, state.bk}\n",
    "                if state.wp is not None:\n",
    "                    occupied.add(state.wp)\n",
    "                if self.on_board(fwd) and fwd not in occupied:\n",
    "                    actions.append(Action('P', state.wp, fwd))\n",
    "                # captures\n",
    "                for dst in self.pawn_attack_squares(state.wp):\n",
    "                    if dst == state.bk:\n",
    "                        actions.append(Action('P', state.wp, dst))\n",
    "\n",
    "        else:  # Black to move\n",
    "            # Black king moves\n",
    "            for dst in self.king_moves(state.bk):\n",
    "                # cannot move onto own piece (none)\n",
    "                # cannot move onto white king\n",
    "                if dst == state.wk:\n",
    "                    continue\n",
    "                # cannot move adjacent to white king\n",
    "                if self.kings_adjacent(dst, state.wk):\n",
    "                    continue\n",
    "                # cannot move onto pawn? black may capture pawn\n",
    "                # black can capture pawn by moving onto it\n",
    "                actions.append(Action('K', state.bk, dst))\n",
    "        return actions\n",
    "\n",
    "    def _apply_action_once(self, state: State, action: Action) -> State:\n",
    "        wk = state.wk\n",
    "        wp = state.wp\n",
    "        bk = state.bk\n",
    "        promoted = state.promoted\n",
    "        to_move = state.to_move\n",
    "\n",
    "        if action.piece == 'K' and to_move == 'W':\n",
    "            wk = action.dst\n",
    "        elif action.piece == 'P' and to_move == 'W':\n",
    "            # move pawn (may capture or promote)\n",
    "            wp = action.dst\n",
    "            # promotion check: if pawn reaches last rank (row 0 for pawn_dir=-1)\n",
    "            if wp[0] == 0 and not promoted:\n",
    "                # We choose to terminate immediately on promotion; mark promoted\n",
    "                promoted = True\n",
    "        elif action.piece == 'K' and to_move == 'B':\n",
    "            # if black moves onto pawn square, capture\n",
    "            if wp is not None and action.dst == wp:\n",
    "                wp = None\n",
    "            bk = action.dst\n",
    "        # toggle to_move\n",
    "        next_to_move = 'B' if to_move == 'W' else 'W'\n",
    "        return State(wk=wk, wp=wp, bk=bk, to_move=next_to_move, promoted=promoted)\n",
    "\n",
    "    def transitions(self, state: State, action: Action):\n",
    "        \"\"\"\n",
    "        Return list of (prob, next_state, reward, done) tuples for given state and action.\n",
    "        We model Black as a uniformly random opponent when it is Black's turn after our action.\n",
    "        \"\"\"\n",
    "        # Apply the immediate action\n",
    "        mid_state = self._apply_action_once(state, action)\n",
    "        # Check terminal conditions immediately after the move (e.g., promotion)\n",
    "        # Promotion chosen to terminate immediately with reward +10 for White\n",
    "        if mid_state.promoted and state.to_move == 'W':\n",
    "            # White promoted -> immediate reward\n",
    "            return [(1.0, mid_state, 10.0, True)]\n",
    "\n",
    "        # If pawn got captured by this action (shouldn't happen on white move), handle\n",
    "        if mid_state.wp is None and state.wp is not None and state.to_move == 'B':\n",
    "            # black captured pawn\n",
    "            return [(1.0, mid_state, -10.0, True)]\n",
    "\n",
    "        # If after our action it's Black to move, we must consider black responses\n",
    "        if mid_state.to_move == 'B':\n",
    "            black_actions = self.legal_actions(mid_state)\n",
    "            if not black_actions:\n",
    "                # If black has no legal actions: if in check -> checkmate; else stalemate\n",
    "                if self.in_check(mid_state, 'B'):\n",
    "                    # White delivered checkmate\n",
    "                    return [(1.0, mid_state, 10.0, True)]\n",
    "                else:\n",
    "                    return [(1.0, mid_state, 0.0, True)]\n",
    "            probs = 1.0 / len(black_actions)\n",
    "            results = []\n",
    "            for ba in black_actions:\n",
    "                ns = self._apply_action_once(mid_state, ba)\n",
    "                # if black captured pawn\n",
    "                if ns.wp is None and mid_state.wp is not None:\n",
    "                    results.append((probs, ns, -10.0, True))\n",
    "                    continue\n",
    "                # check for checkmate or stalemate when back to white\n",
    "                white_actions = self.legal_actions(ns)\n",
    "                if not white_actions:\n",
    "                    if self.in_check(ns, 'W'):\n",
    "                        # black somehow checkmates white (unlikely with only king)\n",
    "                        results.append((probs, ns, -10.0, True))\n",
    "                    else:\n",
    "                        results.append((probs, ns, 0.0, True))\n",
    "                else:\n",
    "                    results.append((probs, ns, 0.0, False))\n",
    "            return results\n",
    "        else:\n",
    "            # If it becomes White to move (e.g., black action returned immediately), just return\n",
    "            return [(1.0, mid_state, 0.0, False)]\n",
    "\n",
    "    # Transition / step (single deterministic action application)\n",
    "    def step(self, state: State, action: Action):\n",
    "        \"\"\"Apply action to state and return one sample (next_state, reward, done, info).\n",
    "        This picks one of the possible stochastic outcomes (if any) at random. For DP we will use transitions().\"\"\"\n",
    "        trans = self.transitions(state, action)\n",
    "        # sample according to probabilities\n",
    "        p = np.random.random()\n",
    "        cum = 0.0\n",
    "        for prob, ns, r, done in trans:\n",
    "            cum += prob\n",
    "            if p <= cum:\n",
    "                return ns, r, done, {}\n",
    "        # fallback\n",
    "        prob, ns, r, done = trans[-1]\n",
    "        return ns, r, done, {}\n",
    "\n",
    "    def reset(self, initial: Optional[State] = None):\n",
    "        # Default starting configuration (students should document their chosen initial state)\n",
    "        if initial is not None:\n",
    "            self.state = initial\n",
    "            self.steps = 0\n",
    "            return self.state\n",
    "        # we pick a reasonable default for 4x4 board\n",
    "        if self.N == 4:\n",
    "            wk = (3, 0)\n",
    "            wp = (2, 1)\n",
    "            bk = (0, 3)\n",
    "        else:\n",
    "            wk = (4, 0)\n",
    "            wp = (3, 1)\n",
    "            bk = (0, 4)\n",
    "        self.state = State(wk=wk, wp=wp, bk=bk, to_move='W', promoted=False)\n",
    "        self.steps = 0\n",
    "        return self.state\n",
    "\n",
    "    def render(self, state: Optional[State] = None):\n",
    "        s = state or self.state\n",
    "        board = [['.' for _ in range(self.N)] for _ in range(self.N)]\n",
    "        if s.wp is not None:\n",
    "            r, c = s.wp\n",
    "            board[r][c] = 'P' if not s.promoted else 'Q'\n",
    "        wr, wc = s.wk\n",
    "        board[wr][wc] = 'K'\n",
    "        br, bc = s.bk\n",
    "        board[br][bc] = 'k'\n",
    "        print(f\"To move: {s.to_move}  promoted: {s.promoted}\")\n",
    "        for r in range(self.N):\n",
    "            print(' '.join(board[r]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fcc5d",
   "metadata": {},
   "source": [
    "## How rules are enforced (explicit description)\n",
    "\n",
    "This section explains how each game rule required by the assignment is enforced in the `MiniChessEnv` implementation:\n",
    "\n",
    "- Legal moves for King and Pawn:\n",
    "  - `king_moves(pos)` generates all 8-neighborhood moves; `pawn_forward(pos)` and `pawn_attack_squares(pos)` provide pawn forward and capture squares. `legal_actions(state)` filters these by board bounds and occupation.\n",
    "- Pawn forward move and diagonal capture:\n",
    "  - Pawn forward: allowed only if the forward square is on-board and unoccupied. Pawn capture: allowed if the black king occupies a pawn attack square.\n",
    "- Turn switching (White / Black):\n",
    "  - `_apply_action_once` toggles `to_move` between `'W'` and `'B'` after applying an action.\n",
    "- Kings never adjacent:\n",
    "  - `kings_adjacent(wk,bk)` checks adjacency; `legal_actions` disallows king moves that result in adjacency.\n",
    "- Kings never move into check:\n",
    "  - For White king moves, `legal_actions` rejects moves where the destination is adjacent to the black king (attacked square). For Black moves, adjacency is checked similarly against the White king.\n",
    "- Terminal conditions:\n",
    "  - Pawn promotion: detected in `_apply_action_once`; current modeling treats promotion as immediate termination with reward +10.\n",
    "  - Pawn capture: if Black moves onto pawn square, `transitions` returns a terminal with reward −10.\n",
    "  - Checkmate / Stalemate: when the side to move has no legal actions, `transitions` uses `in_check()` to determine checkmate (terminal +10/−10) vs stalemate (terminal 0).\n",
    "  - Move-limit draw: `MiniChessEnv` tracks `self.max_steps` and can be extended to terminate with 0 after exceeding the limit (not needed for small enumerations but can be enabled).\n",
    "\n",
    "These enforcement details are implemented directly in `legal_actions`, `_apply_action_once`, `transitions`, and `in_check`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b8921af",
   "metadata": {
    "id": "0b8921af"
   },
   "outputs": [],
   "source": [
    "# State encoding & Listing - 1 mark\n",
    "\n",
    "class StateIndexer:\n",
    "    def __init__(self, states: List[State]):\n",
    "        # Build bidirectional maps between State and index\n",
    "        self.states = list(states)\n",
    "        self.s2i: Dict[Any, int] = {s.as_tuple(): i for i, s in enumerate(self.states)}\n",
    "        self.i2s: Dict[int, State] = {i: s for i, s in enumerate(self.states)}\n",
    "\n",
    "    def _build(self):\n",
    "        # Already built in __init__\n",
    "        pass\n",
    "\n",
    "    def encode(self, state: State) -> int:\n",
    "        return self.s2i[state.as_tuple()]\n",
    "\n",
    "    def decode(self, idx: int) -> State:\n",
    "        return self.i2s[idx]\n",
    "\n",
    "# List all reachable states (BFS) from an initial state - 1 mark\n",
    "\n",
    "def list_reachable(env: MiniChessEnv, initial: State):\n",
    "    \"\"\"Breadth-first search of reachable states using all legal actions and transitions.\n",
    "    We include non-terminal mid-states as well. Because transitions can create stochastic branches\n",
    "    (black random moves), we include all resulting next-states seen.\n",
    "    \"\"\"\n",
    "    q = deque()\n",
    "    seen = set()\n",
    "    q.append(initial)\n",
    "    seen.add(initial.as_tuple())\n",
    "    results = [initial]\n",
    "    while q:\n",
    "        s = q.popleft()\n",
    "        actions = env.legal_actions(s)\n",
    "        for a in actions:\n",
    "            for prob, ns, r, done in env.transitions(s, a):\n",
    "                key = ns.as_tuple()\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    results.append(ns)\n",
    "                    if not done:\n",
    "                        q.append(ns)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44321269",
   "metadata": {
    "id": "44321269"
   },
   "outputs": [],
   "source": [
    "# Value Iteration / Policy Iteration - 1 mark\n",
    "\n",
    "def value_iteration(env: MiniChessEnv, states: List[State], gamma: float = 0.99, theta: float = 1e-3, max_iters: int = 10000):\n",
    "    \"\"\"Perform value iteration on the provided states.\n",
    "    Returns (V, policy, stats) where stats contains iterations, final_delta, runtime\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    indexer = StateIndexer(states)\n",
    "    V = {s.as_tuple(): 0.0 for s in states}\n",
    "    policy: Dict[Any, Action] = {}\n",
    "\n",
    "    iteration = 0\n",
    "    while iteration < max_iters:\n",
    "        delta = 0.0\n",
    "        for s in states:\n",
    "            key = s.as_tuple()\n",
    "            actions = env.legal_actions(s)\n",
    "            if not actions:\n",
    "                # terminal-like\n",
    "                if env.in_check(s, s.to_move):\n",
    "                    v_new = -10.0 if s.to_move == 'W' else 10.0\n",
    "                else:\n",
    "                    v_new = 0.0\n",
    "                V[key] = v_new\n",
    "                continue\n",
    "            best_a_val = -1e9\n",
    "            best_a = None\n",
    "            for a in actions:\n",
    "                q_sa = 0.0\n",
    "                for prob, ns, r, done in env.transitions(s, a):\n",
    "                    if done:\n",
    "                        q_sa += prob * r\n",
    "                    else:\n",
    "                        q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                if q_sa > best_a_val:\n",
    "                    best_a_val = q_sa\n",
    "                    best_a = a\n",
    "            delta = max(delta, abs(V[key] - best_a_val))\n",
    "            V[key] = best_a_val\n",
    "            if s.to_move == 'W' and best_a is not None:\n",
    "                policy[key] = best_a\n",
    "        iteration += 1\n",
    "        if delta < theta:\n",
    "            break\n",
    "    runtime = time.time() - start\n",
    "    stats = {'algorithm': 'Value Iteration', 'iterations': iteration, 'final_delta': delta, 'runtime': runtime}\n",
    "    return V, policy, stats\n",
    "\n",
    "\n",
    "def policy_evaluation(env: MiniChessEnv, states: List[State], policy: Dict[Any, Action], gamma: float = 0.99, theta: float = 1e-3):\n",
    "    \"\"\"Evaluate a fixed policy (policy maps White states to actions).\n",
    "    Returns (V, final_delta)\n",
    "    \"\"\"\n",
    "    V = {s.as_tuple(): 0.0 for s in states}\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        for s in states:\n",
    "            key = s.as_tuple()\n",
    "            actions = env.legal_actions(s)\n",
    "            if not actions:\n",
    "                if env.in_check(s, s.to_move):\n",
    "                    v_new = -10.0 if s.to_move == 'W' else 10.0\n",
    "                else:\n",
    "                    v_new = 0.0\n",
    "            else:\n",
    "                if s.to_move == 'W':\n",
    "                    a = policy.get(key)\n",
    "                    if a is None:\n",
    "                        # if no policy action, pick first\n",
    "                        a = actions[0]\n",
    "                    q_sa = 0.0\n",
    "                    for prob, ns, r, done in env.transitions(s, a):\n",
    "                        if done:\n",
    "                            q_sa += prob * r\n",
    "                        else:\n",
    "                            q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                    v_new = q_sa\n",
    "                else:\n",
    "                    # Black to move: treat as uniform random\n",
    "                    q_val = 0.0\n",
    "                    for ba in actions:\n",
    "                        for prob, ns, r, done in env.transitions(s, ba):\n",
    "                            if done:\n",
    "                                q_val += (1.0 / len(actions)) * prob * r\n",
    "                            else:\n",
    "                                q_val += (1.0 / len(actions)) * prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                    v_new = q_val\n",
    "            delta = max(delta, abs(V[key] - v_new))\n",
    "            V[key] = v_new\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V, delta\n",
    "\n",
    "\n",
    "def policy_improvement(env: MiniChessEnv, states: List[State], V: Dict[Any, float], gamma: float = 0.99):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if s.to_move != 'W':\n",
    "            continue\n",
    "        actions = env.legal_actions(s)\n",
    "        if not actions:\n",
    "            continue\n",
    "        best_val = -1e9\n",
    "        best_a = None\n",
    "        for a in actions:\n",
    "            q_sa = 0.0\n",
    "            for prob, ns, r, done in env.transitions(s, a):\n",
    "                if done:\n",
    "                    q_sa += prob * r\n",
    "                else:\n",
    "                    q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "            if q_sa > best_val:\n",
    "                best_val = q_sa\n",
    "                best_a = a\n",
    "        policy[s.as_tuple()] = best_a\n",
    "    return policy\n",
    "\n",
    "\n",
    "def policy_iteration(env: MiniChessEnv, states: List[State], gamma: float = 0.99, theta: float = 1e-3, max_iters: int = 100):\n",
    "    \"\"\"Classic policy iteration focusing on White's choices.\n",
    "    Returns V, policy, stats where stats contains final_delta as measured during final evaluation.\n",
    "    \"\"\"\n",
    "    # initialize random policy for White states\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if s.to_move == 'W':\n",
    "            acts = env.legal_actions(s)\n",
    "            if acts:\n",
    "                policy[s.as_tuple()] = acts[0]\n",
    "    start = time.time()\n",
    "    it = 0\n",
    "    final_delta = None\n",
    "    while it < max_iters:\n",
    "        # policy evaluation (returns V and last delta)\n",
    "        V, delta = policy_evaluation(env, states, policy, gamma=gamma, theta=theta)\n",
    "        # policy improvement\n",
    "        new_policy = policy_improvement(env, states, V, gamma=gamma)\n",
    "        if new_policy == policy:\n",
    "            final_delta = delta\n",
    "            break\n",
    "        policy = new_policy\n",
    "        it += 1\n",
    "    # if not converged by equality, still run a final evaluation to get delta\n",
    "    if final_delta is None:\n",
    "        V, delta = policy_evaluation(env, states, policy, gamma=gamma, theta=theta)\n",
    "        final_delta = delta\n",
    "    runtime = time.time() - start\n",
    "    stats = {'algorithm': 'Policy Iteration', 'iterations': it, 'final_delta': final_delta, 'runtime': runtime}\n",
    "    return V, policy, stats\n",
    "\n",
    "\n",
    "# Helper: simulate policy from a start state and print sequence\n",
    "\n",
    "def simulate_policy(env: MiniChessEnv, start: State, policy: Dict[Any, Action], max_steps: int = 50):\n",
    "    s = start\n",
    "    seq = [s]\n",
    "    for t in range(max_steps):\n",
    "        key = s.as_tuple()\n",
    "        if s.to_move == 'W':\n",
    "            a = policy.get(key)\n",
    "            if a is None:\n",
    "                acts = env.legal_actions(s)\n",
    "                if not acts:\n",
    "                    break\n",
    "                a = acts[0]\n",
    "            ns, r, done, _ = env.step(s, a)\n",
    "            seq.append((a, ns, r, done))\n",
    "            if done:\n",
    "                break\n",
    "            s = ns\n",
    "        else:\n",
    "            # Black random move\n",
    "            acts = env.legal_actions(s)\n",
    "            if not acts:\n",
    "                break\n",
    "            a = acts[np.random.randint(len(acts))]\n",
    "            ns, r, done, _ = env.step(s, a)\n",
    "            seq.append((a, ns, r, done))\n",
    "            if done:\n",
    "                break\n",
    "            s = ns\n",
    "    return seq\n",
    "\n",
    "# Runner to compare VI and PI and produce convergence stats and heatmaps\n",
    "\n",
    "def run_experiment(env: MiniChessEnv, initial: State):\n",
    "    states = list_reachable(env, initial)\n",
    "    print(f\"Enumerated {len(states)} reachable states\")\n",
    "\n",
    "    V_vi, pi_vi, stats_vi = value_iteration(env, states, gamma=0.99, theta=1e-3)\n",
    "    print(\"Value Iteration stats:\", stats_vi)\n",
    "\n",
    "    V_pi, pi_pi, stats_pi = policy_iteration(env, states, gamma=0.99, theta=1e-3)\n",
    "    print(\"Policy Iteration stats:\", stats_pi)\n",
    "\n",
    "    return {\n",
    "        'states': states,\n",
    "        'vi': (V_vi, pi_vi, stats_vi),\n",
    "        'pi': (V_pi, pi_pi, stats_pi),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15d4bca3",
   "metadata": {
    "id": "15d4bca3"
   },
   "outputs": [],
   "source": [
    "# Visualization - 0.5 mark\n",
    "\n",
    "def plot_value(env: MiniChessEnv, V: Dict[Any, float], fixed_wp: Pos, fixed_bk: Pos):\n",
    "    \"\"\"Fix pawn and black king positions; vary white king position and show heatmap of V(s).\n",
    "    White king positions that overlap pawn or black king are skipped.\n",
    "    \"\"\"\n",
    "    N = env.N\n",
    "    heat = np.full((N, N), np.nan)\n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            wk = (r, c)\n",
    "            # skip invalid overlap\n",
    "            if wk == fixed_wp or wk == fixed_bk:\n",
    "                continue\n",
    "            s = State(wk=wk, wp=fixed_wp, bk=fixed_bk, to_move='W', promoted=False)\n",
    "            key = s.as_tuple()\n",
    "            if key in V:\n",
    "                heat[r, c] = V[key]\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title('Value heatmap for White to move (higher better)')\n",
    "    plt.imshow(heat, origin='upper', cmap='coolwarm')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "832c37f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results table and extra visualizations\n",
    "import pandas as pd\n",
    "\n",
    "def print_results_table(stats_vi, stats_pi):\n",
    "    rows = [\n",
    "        {'Algorithm': stats_vi.get('algorithm', 'Value Iteration'),\n",
    "         'Iterations': stats_vi.get('iterations'),\n",
    "         'Final ΔV': stats_vi.get('final_delta'),\n",
    "         'Runtime (s)': round(stats_vi.get('runtime', 0.0), 4)},\n",
    "        {'Algorithm': stats_pi.get('algorithm', 'Policy Iteration'),\n",
    "         'Iterations': stats_pi.get('iterations'),\n",
    "         'Final ΔV': stats_pi.get('final_delta'),\n",
    "         'Runtime (s)': round(stats_pi.get('runtime', 0.0), 4)},\n",
    "    ]\n",
    "    df = pd.DataFrame(rows)\n",
    "    display(df)\n",
    "\n",
    "# Two heatmaps side-by-side for different fixed Black King positions\n",
    "\n",
    "def plot_two_heatmaps(env: MiniChessEnv, V: Dict[Any, float], fixed_wp: Pos, fixed_bk1: Pos, fixed_bk2: Pos):\n",
    "    N = env.N\n",
    "    heat1 = np.full((N, N), np.nan)\n",
    "    heat2 = np.full((N, N), np.nan)\n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            wk = (r, c)\n",
    "            if wk == fixed_wp or wk == fixed_bk1:\n",
    "                pass\n",
    "            else:\n",
    "                s1 = State(wk=wk, wp=fixed_wp, bk=fixed_bk1, to_move='W', promoted=False)\n",
    "                key1 = s1.as_tuple()\n",
    "                if key1 in V:\n",
    "                    heat1[r, c] = V[key1]\n",
    "            if wk == fixed_wp or wk == fixed_bk2:\n",
    "                pass\n",
    "            else:\n",
    "                s2 = State(wk=wk, wp=fixed_wp, bk=fixed_bk2, to_move='W', promoted=False)\n",
    "                key2 = s2.as_tuple()\n",
    "                if key2 in V:\n",
    "                    heat2[r, c] = V[key2]\n",
    "    # compute combined vmin/vmax safely\n",
    "    vals = np.concatenate([heat1[~np.isnan(heat1)], heat2[~np.isnan(heat2)]]) if (np.any(~np.isnan(heat1)) or np.any(~np.isnan(heat2))) else np.array([0.0])\n",
    "    vmin = float(np.nanmin(vals))\n",
    "    vmax = float(np.nanmax(vals))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(9, 4))\n",
    "    for ax, heat, title, bk in zip(axes, [heat1, heat2], ['BK at pos A', 'BK at pos B'], [fixed_bk1, fixed_bk2]):\n",
    "        im = ax.imshow(heat, origin='upper', cmap='coolwarm', vmin=vmin, vmax=vmax)\n",
    "        ax.set_title(f\"{title}  (WP={fixed_wp}, BK={bk})\")\n",
    "        ax.set_xlabel('col (0→)')\n",
    "        ax.set_ylabel('row (0→)')\n",
    "        # annotate coordinates\n",
    "        ax.set_xticks(np.arange(N))\n",
    "        ax.set_yticks(np.arange(N))\n",
    "        for (i, j), val in np.ndenumerate(heat):\n",
    "            if not np.isnan(val):\n",
    "                ax.text(j, i, f\"{val:.2f}\", ha='center', va='center', fontsize=8, color='black')\n",
    "    fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.6)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66125bdb",
   "metadata": {
    "id": "66125bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "To move: W  promoted: False\n",
      ". . . k\n",
      ". . . .\n",
      ". P . .\n",
      "K . . .\n",
      "\n",
      "Enumerated 993 reachable states\n",
      "Value Iteration stats: {'algorithm': 'Value Iteration', 'iterations': 5, 'final_delta': 0.0, 'runtime': 0.33735132217407227}\n",
      "Policy Iteration stats: {'algorithm': 'Policy Iteration', 'iterations': 3, 'final_delta': 0.0, 'runtime': 2.026747941970825}\n",
      "\n",
      "Convergence summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Iterations</th>\n",
       "      <th>Final ΔV</th>\n",
       "      <th>Runtime (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Value Iteration</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Policy Iteration</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Algorithm  Iterations  Final ΔV  Runtime (s)\n",
       "0   Value Iteration           5       0.0       0.3374\n",
       "1  Policy Iteration           3       0.0       2.0267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Examples from Value Iteration policy:\n",
      "State: State(wk=(3, 0), wp=(2, 1), bk=(0, 3), to_move='W', promoted=False) -> V=9.900, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(0, 2), to_move='W', promoted=False) -> V=9.875, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(1, 2), to_move='W', promoted=False) -> V=9.884, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(1, 3), to_move='W', promoted=False) -> V=9.900, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(3, 1), wp=(2, 1), bk=(0, 2), to_move='W', promoted=False) -> V=9.801, best action: K (3, 1)->(2, 2)\n",
      "State: State(wk=(3, 1), wp=(2, 1), bk=(1, 2), to_move='W', promoted=False) -> V=9.884, best action: P (2, 1)->(1, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shara\\AppData\\Local\\Temp\\ipykernel_7036\\1887753687.py:59: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulated rollout 1 (Value Iteration policy) from initial state:\n",
      "To move: W  promoted: False\n",
      ". . . k\n",
      ". . . .\n",
      ". P . .\n",
      "K . . .\n",
      "\n",
      "Action: P (2, 1)->(1, 1)  reward=0.0 done=False\n",
      "To move: W  promoted: False\n",
      ". . k .\n",
      ". P . .\n",
      ". . . .\n",
      "K . . .\n",
      "\n",
      "Action: P (1, 1)->(0, 1)  reward=10.0 done=True\n",
      "To move: B  promoted: True\n",
      ". Q k .\n",
      ". . . .\n",
      ". . . .\n",
      "K . . .\n",
      "\n",
      "\n",
      "Simulated rollout 2 (Value Iteration policy) from alternate state:\n",
      "To move: W  promoted: False\n",
      ". . . k\n",
      ". . . .\n",
      ". K . .\n",
      ". . . .\n",
      "\n",
      "Action: K (2, 1)->(1, 0)  reward=0.0 done=False\n",
      "To move: W  promoted: False\n",
      ". . . .\n",
      "K . k .\n",
      ". P . .\n",
      ". . . .\n",
      "\n",
      "Action: P (2, 1)->(1, 1)  reward=0.0 done=False\n",
      "To move: W  promoted: False\n",
      ". . . .\n",
      "K P . k\n",
      ". . . .\n",
      ". . . .\n",
      "\n",
      "Action: P (1, 1)->(0, 1)  reward=10.0 done=True\n",
      "To move: B  promoted: True\n",
      ". Q . .\n",
      "K . . k\n",
      ". . . .\n",
      ". . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main Usage - 1 mark\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create environment (default 4x4 board)\n",
    "    env = MiniChessEnv(board_size=4)\n",
    "\n",
    "    # Documenting choices:\n",
    "    # - Board chosen: 4x4 (default). Pawn moves upwards (decreasing row index).\n",
    "    # - Promotion terminates immediately with reward +10.\n",
    "    # - Black acts as a uniformly random opponent for DP modeling.\n",
    "\n",
    "    # Reset to default initial state\n",
    "    initial = env.reset()\n",
    "    print(\"Initial state:\")\n",
    "    env.render(initial)\n",
    "\n",
    "    # Run full experiment (enumerate states, run VI and PI)\n",
    "    results = run_experiment(env, initial)\n",
    "    states = results['states']\n",
    "    V_vi, pi_vi, stats_vi = results['vi']\n",
    "    V_pi, pi_pi, stats_pi = results['pi']\n",
    "\n",
    "    # Print results table\n",
    "    print('\\nConvergence summary:')\n",
    "    print_results_table(stats_vi, stats_pi)\n",
    "\n",
    "    # Show a few example state values and chosen actions (Value Iteration policy)\n",
    "    print('\\nExamples from Value Iteration policy:')\n",
    "    cnt = 0\n",
    "    for s in states:\n",
    "        key = s.as_tuple()\n",
    "        if key in pi_vi and s.to_move == 'W':\n",
    "            a = pi_vi[key]\n",
    "            print(f\"State: {s} -> V={V_vi[key]:.3f}, best action: {a.piece} {a.src}->{a.dst}\")\n",
    "            cnt += 1\n",
    "            if cnt >= 6:\n",
    "                break\n",
    "\n",
    "    # Visualize two heatmaps with different Black King placements\n",
    "    if initial.wp is not None:\n",
    "        bk_a = initial.bk\n",
    "        # choose an alternate BK placement (mirror or nearby) for comparison\n",
    "        bk_b = (0, max(0, initial.bk[1]-1)) if env.N > 1 else initial.bk\n",
    "        plot_two_heatmaps(env, V_vi, fixed_wp=initial.wp, fixed_bk1=bk_a, fixed_bk2=bk_b)\n",
    "\n",
    "    # Simulate two policy rollouts from different starting states\n",
    "    print('\\nSimulated rollout 1 (Value Iteration policy) from initial state:')\n",
    "    seq1 = simulate_policy(env, initial, pi_vi, max_steps=50)\n",
    "    for item in seq1:\n",
    "        if isinstance(item, State):\n",
    "            env.render(item)\n",
    "        else:\n",
    "            a, ns, r, done = item\n",
    "            print(f\"Action: {a.piece} {a.src}->{a.dst}  reward={r} done={done}\")\n",
    "            env.render(ns)\n",
    "    \n",
    "    # Create a second starting state (move white king slightly forward if legal) to show another policy example\n",
    "    alt_wk = (max(0, initial.wk[0]-1), min(env.N-1, initial.wk[1]+1))\n",
    "    alt_state = State(wk=alt_wk, wp=initial.wp, bk=initial.bk, to_move='W', promoted=False)\n",
    "    print('\\nSimulated rollout 2 (Value Iteration policy) from alternate state:')\n",
    "    seq2 = simulate_policy(env, alt_state, pi_vi, max_steps=50)\n",
    "    for item in seq2:\n",
    "        if isinstance(item, State):\n",
    "            env.render(item)\n",
    "        else:\n",
    "            a, ns, r, done = item\n",
    "            print(f\"Action: {a.piece} {a.src}->{a.dst}  reward={r} done={done}\")\n",
    "            env.render(ns)\n",
    "\n",
    "    # Save summary artifacts if desired (optional)\n",
    "    # You can save V_vi heatmap images or the DataFrame above to files here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9120f8",
   "metadata": {},
   "source": [
    "# Result Discussion and descriptive answers, conclusion - 1 mark\n",
    "\n",
    "**Summary of results (example run on 4×4 board)**\n",
    "\n",
    "- Reachable states enumerated from the chosen initial state: 993 (BFS over legal moves and stochastic black responses).\n",
    "- Value Iteration: converged in 5 iterations (final max-value change ≈ 0.0); runtime ≈ 0.32 s.\n",
    "- Policy Iteration: converged in 3 policy-improvement steps; runtime ≈ 2.06 s.\n",
    "\n",
    "**Deliverable checklist & descriptive answers**\n",
    "\n",
    "- Custom environment: `MiniChessEnv` implements `reset()`, `step()` (deterministic sample via `transitions()`), and `render()`. It enforces legal moves, pawn captures, promotion (chosen to terminate immediately), kings-adjacency rule, and basic check/checkmate/stalemate detection.\n",
    "\n",
    "- Initial configuration rule used: (ID last-digit rule) this run used the 0–4 branch — WK and BK in opposite corners, WP on the rank closest to White. This choice favors a straightforward promotion race and keeps states interpretable.\n",
    "\n",
    "- DP solutions implemented: `value_iteration()` and `policy_iteration()` producing `V*(s)` and a greedy policy `π*(s)` for White. Stopping criterion: max change < θ (default 1e-3).\n",
    "\n",
    "- Convergence and runtime: VI converged quickly (few iterations) on this small MDP; PI required fewer improvement rounds but more per-iteration work — both are practical for 4×4.\n",
    "\n",
    "- Visual & qualitative analysis: heatmaps (fixed pawn + fixed BK, varying WK) show higher values when the White king is near the pawn and far from the Black king. Policies tend to advance the pawn when safe and use the king to block/capture threats.\n",
    "\n",
    "**Descriptive answers to analysis questions**\n",
    "\n",
    "1. How does state design affect convergence?\n",
    "- Compact state encoding and early terminal handling (promotion-as-termination) reduce the enumerated state-space and speed up backups. Adding flags (promoted, move counts) increases state count and slows DP.\n",
    "\n",
    "2. Reward shaping effects?\n",
    "- Strong terminal rewards (+10 for promotion/checkmate, −10 for pawn capture) create clear value gradients and fast convergence. Smaller rewards or sparse signals would need more iterations and make policies less decisive.\n",
    "\n",
    "3. Why use random Black opponent in this MDP?\n",
    "- Modeling Black as uniform-random converts the game into an MDP (stochastic transitions) suitable for DP; an adversarial Black requires minimax or robust formulations.\n",
    "\n",
    "**Limitations & suggestions**\n",
    "\n",
    "- Promotion-as-termination simplifies analysis but omits post-promotion play; to study full endgames, implement Queen moves and continue episodes.\n",
    "- Scaling to larger boards or extra pieces quickly explodes state-space; consider function approximation or sample-based RL for larger problems.\n",
    "\n",
    "**Conclusion (1 mark)**\n",
    "\n",
    "This notebook implements a complete MiniChess MDP and applies tabular dynamic programming to obtain high-quality policies for White on tiny boards. Results show that advancing the pawn toward promotion (when supported by the king) is the dominant strategy. While DP works well for the reduced game, full chess requires approximate, sample-based, or search-driven methods due to the curse of dimensionality.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
