{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd14fc5",
   "metadata": {
    "id": "5cd14fc5"
   },
   "source": [
    "## Mini Chess Solver Using Dynamic Programming - Total 7 Marks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49524177",
   "metadata": {
    "id": "49524177"
   },
   "source": [
    "### Problem Statement\n",
    "\n",
    "Design and implement a reinforcement learning agent using dynamic programming (value iteration or policy iteration) to compute an optimal policy for a simplified chess game. The agent plays as White and must learn how to convert an advantage into a win or at least avoid a loss in a MiniChess game against a defensive opponent. The problem must be modelled as a finite MDP. Register number of first student in a group (alphabetically sorted) will be considered for configuration design.\n",
    "The student will:\n",
    "* Implement a custom Mini Chess environment.\n",
    "* Use dynamic programming to compute the optimal value function and policy.\n",
    "* Analyze how state design and reward shaping affect the learned policy and convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a8d3b7",
   "metadata": {
    "id": "f2a8d3b7"
   },
   "source": [
    "### Scenario\n",
    "\n",
    "You are building a “Mini Chess Game” for beginner players. The coach focuses on a small, tractable game:\n",
    "* White: King + Pawn\n",
    "* Black: King\n",
    "* Board: 4×4 or 5×5 MiniChess board\n",
    "* White moves first and tries to either:\n",
    "    * Promote the pawn and then deliver checkmate, or\n",
    "    * Force a checkmate directly (if possible)\n",
    "\n",
    "Black tries to prevent this by blocking the pawn, chasing the white king, or capturing the pawn. The game is restricted to this small set of pieces and a tiny board."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf39bfe",
   "metadata": {
    "id": "fbf39bfe"
   },
   "source": [
    "### Environment Description\n",
    "#### Board and Pieces\n",
    "* Board size:\n",
    "    * If the student roll number / registration number is even: use a 4×4 board (rows 0–3, cols 0–3).\n",
    "    * If odd: use a 5×5 board (rows 0–4, cols 0–4).\n",
    "* Pieces always present:\n",
    "    * White King (WK)\n",
    "    * White Pawn (WP)\n",
    "    * Black King (BK)\n",
    "    * No castling, no en passant, no promotion to anything other than Queen.\n",
    "* Legal Moves\n",
    "    * Kings move like normal chess kings - one square in any direction (8- neighborhood), staying on the board.\n",
    "    * Pawn:\n",
    "        * Moves one square forward (towards larger row index or smaller row index – the student must choose and clearly document a convention).\n",
    "        * Captures diagonally forward by one square.\n",
    "    * All usual constraints apply:\n",
    "        * Kings cannot move into check.\n",
    "        * Two kings may never occupy adjacent squares (illegal state).\n",
    "        * A piece cannot move through other pieces.\n",
    "* Episode Termination\n",
    "    * An episode ends when any of the following happens:\n",
    "        * Checkmate (White checkmates Black).\n",
    "        * Stalemate (side to move has no legal moves but is not in check).\n",
    "        * Pawn Capture (Black captures the White pawn).\n",
    "        * Pawn Promotion (White pawn reaches last rank and becomes a Queen). After promotion, they may either:\n",
    "                * (a) terminate immediately with a reward, or\n",
    "                * (b) continue playing with a Queen replacing the pawn.\n",
    "        * The student must choose one approach and justify it.\n",
    "        * Move limit exceeded (e.g., 20 or 30 plies) – draw\n",
    "1. State Space\n",
    "\n",
    "* Each state should minimally encode:\n",
    "    * Coordinates of WK: (r_wk, c_wk)\n",
    "    * Coordinates of WP (or a special value if promoted/captured): (r_wp, c_wp) or status flag\n",
    "    * Coordinates of BK: (r_bk, c_bk)\n",
    "    * Player to move: {White, Black}\n",
    "    * Any additional flags that can be necessary like,\n",
    "        * Has the pawn promoted?\n",
    "        * Check / checkmate / stalemate indicators.\n",
    "* The student must:\n",
    "    * Describe the state representation clearly.\n",
    "2. Action Space\n",
    "    * For each state, actions are the legal moves for the side to move:\n",
    "        * Move King to a legal square\n",
    "        * Move Pawn / promoted Queen\n",
    "    * The student must implement a function that, given a state, returns all legal actions.\n",
    "3. Rewards\n",
    "* The student has to define the reward schemes like:\n",
    "    * White checkmates Black: +10\n",
    "    * Pawn gets captured: -10\n",
    "    * Stalemate or draw by move limit: 0\n",
    "    * All non-terminal moves: 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10018a",
   "metadata": {
    "id": "6c10018a"
   },
   "source": [
    "**Team Members:**\n",
    "- 2024AD05008 - SHARADANSHU RAJ (100%)\n",
    "- 2024AC05922 - NISHIT UPAL (100%)\n",
    "- 2024AC05923 - NILESH DHAWAL (100%)\n",
    "- 2024ad05002 - SuryaDharshini S (100%)\n",
    "- 2024ac05246 - Suggula Naga Sai teza (100%)%)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddea2384",
   "metadata": {
    "id": "ddea2384"
   },
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import itertools\n",
    "import math\n",
    "import time\n",
    "from collections import deque, defaultdict\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Optional, Iterable, Any\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fab2df65",
   "metadata": {
    "id": "fab2df65"
   },
   "outputs": [],
   "source": [
    "# Basic types and helpers\n",
    "\n",
    "Pos = Tuple[int, int] # (row, col)\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class State:\n",
    "    # define wk,wp,bk and the other things needed\n",
    "    wk: Pos\n",
    "    wp: Optional[Pos] # None if captured or promoted\n",
    "    bk: Pos\n",
    "    to_move: str # 'W' or 'B'\n",
    "    promoted: bool = False\n",
    "\n",
    "    def as_tuple(self):\n",
    "        return (self.wk, self.wp, self.bk, self.to_move, self.promoted)\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Action:\n",
    "    piece: str # 'K' or 'P' or 'Q' (after promotion)\n",
    "    src: Pos\n",
    "    dst: Pos\n",
    "\n",
    "    def as_tuple(self):\n",
    "        return (self.piece, self.src, self.dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ff83072",
   "metadata": {
    "id": "2ff83072"
   },
   "outputs": [],
   "source": [
    "# Define the MiniChess Environment - 1.5 mark\n",
    "class MiniChessEnv:\n",
    "    def __init__(self, board_size: int = 4, pawn_dir: int = -1, max_steps: int = 50):\n",
    "        \"\"\"\n",
    "        board_size: 4 or 5\n",
    "        pawn_dir: -1 means white pawn moves to decreasing row index (upwards)\n",
    "        \"\"\"\n",
    "        self.N = board_size\n",
    "        self.pawn_dir = pawn_dir\n",
    "        self.max_steps = max_steps\n",
    "        self.reset()\n",
    "\n",
    "    # Define functions for board & positions\n",
    "    def on_board(self, pos):\n",
    "        r, c = pos\n",
    "        return 0 <= r < self.N and 0 <= c < self.N\n",
    "\n",
    "    def king_moves(self, pos):\n",
    "        r, c = pos\n",
    "        for dr in (-1, 0, 1):\n",
    "            for dc in (-1, 0, 1):\n",
    "                if dr == 0 and dc == 0:\n",
    "                    continue\n",
    "                nr, nc = r + dr, c + dc\n",
    "                if self.on_board((nr, nc)):\n",
    "                    yield (nr, nc)\n",
    "\n",
    "    def pawn_forward(self, pos):\n",
    "        r, c = pos\n",
    "        return (r + self.pawn_dir, c)\n",
    "\n",
    "    def pawn_attack_squares(self, pos):\n",
    "        r, c = pos\n",
    "        for dc in (-1, 1):\n",
    "            nr, nc = r + self.pawn_dir, c + dc\n",
    "            if self.on_board((nr, nc)):\n",
    "                yield (nr, nc)\n",
    "\n",
    "    # Define functions for game rules and legality checks\n",
    "    def kings_adjacent(self, wk, bk):\n",
    "        return max(abs(wk[0] - bk[0]), abs(wk[1] - bk[1])) <= 1\n",
    "\n",
    "    def is_attacked_by_white(self, square, state):\n",
    "        # Attacked by white king\n",
    "        if max(abs(square[0] - state.wk[0]), abs(square[1] - state.wk[1])) == 1:\n",
    "            return True\n",
    "        # Attacked by pawn (pawn captures diagonally)\n",
    "        if state.wp is not None and not state.promoted:\n",
    "            for s in self.pawn_attack_squares(state.wp):\n",
    "                if s == square:\n",
    "                    return True\n",
    "        # We do not implement full queen attacks because we terminate on promotion\n",
    "        return False\n",
    "\n",
    "    def in_check(self, state, color):\n",
    "        # color is 'W' or 'B' representing side to check\n",
    "        if color == 'B':\n",
    "            # is black king attacked by white?\n",
    "            return self.is_attacked_by_white(state.bk, state)\n",
    "        else:\n",
    "            # white can only be attacked by black king (adjacent) in this simplified game\n",
    "            return max(abs(state.wk[0] - state.bk[0]), abs(state.wk[1] - state.bk[1])) == 1\n",
    "\n",
    "    def legal_actions(self, state: State) -> List[Action]:\n",
    "        \"\"\"Return a list of legal Action objects for the side to move in the given state.\n",
    "        We enforce:\n",
    "          - kings not adjacent\n",
    "          - not moving onto own piece\n",
    "          - kings cannot move into squares attacked by opponent\n",
    "          - pawn moves/captures obey simple rules\n",
    "        \"\"\"\n",
    "        actions: List[Action] = []\n",
    "        if state.to_move == 'W':\n",
    "            # White king moves\n",
    "            for dst in self.king_moves(state.wk):\n",
    "                # cannot move onto own pawn\n",
    "                if state.wp is not None and dst == state.wp:\n",
    "                    continue\n",
    "                # cannot move onto black king\n",
    "                if dst == state.bk:\n",
    "                    continue\n",
    "                # kings cannot be adjacent\n",
    "                if self.kings_adjacent(dst, state.bk):\n",
    "                    continue\n",
    "                # cannot move into check (square attacked by black)\n",
    "                # black only attacks adjacent squares with king\n",
    "                if max(abs(dst[0] - state.bk[0]), abs(dst[1] - state.bk[1])) == 1:\n",
    "                    continue\n",
    "                actions.append(Action('K', state.wk, dst))\n",
    "\n",
    "            # Pawn moves\n",
    "            if state.wp is not None and not state.promoted:\n",
    "                fwd = self.pawn_forward(state.wp)\n",
    "                # forward one if empty and on board\n",
    "                occupied = {state.wk, state.bk}\n",
    "                if state.wp is not None:\n",
    "                    occupied.add(state.wp)\n",
    "                if self.on_board(fwd) and fwd not in occupied:\n",
    "                    actions.append(Action('P', state.wp, fwd))\n",
    "                # captures\n",
    "                for dst in self.pawn_attack_squares(state.wp):\n",
    "                    if dst == state.bk:\n",
    "                        actions.append(Action('P', state.wp, dst))\n",
    "\n",
    "        else:  # Black to move\n",
    "            # Black king moves\n",
    "            for dst in self.king_moves(state.bk):\n",
    "                # cannot move onto own piece (none)\n",
    "                # cannot move onto white king\n",
    "                if dst == state.wk:\n",
    "                    continue\n",
    "                # cannot move adjacent to white king\n",
    "                if self.kings_adjacent(dst, state.wk):\n",
    "                    continue\n",
    "                # cannot move onto pawn? black may capture pawn\n",
    "                # black can capture pawn by moving onto it\n",
    "                actions.append(Action('K', state.bk, dst))\n",
    "        return actions\n",
    "\n",
    "    def _apply_action_once(self, state: State, action: Action) -> State:\n",
    "        wk = state.wk\n",
    "        wp = state.wp\n",
    "        bk = state.bk\n",
    "        promoted = state.promoted\n",
    "        to_move = state.to_move\n",
    "\n",
    "        if action.piece == 'K' and to_move == 'W':\n",
    "            wk = action.dst\n",
    "        elif action.piece == 'P' and to_move == 'W':\n",
    "            # move pawn (may capture or promote)\n",
    "            wp = action.dst\n",
    "            # promotion check: if pawn reaches last rank (row 0 for pawn_dir=-1)\n",
    "            if wp[0] == 0 and not promoted:\n",
    "                # We choose to terminate immediately on promotion; mark promoted\n",
    "                promoted = True\n",
    "        elif action.piece == 'K' and to_move == 'B':\n",
    "            # if black moves onto pawn square, capture\n",
    "            if wp is not None and action.dst == wp:\n",
    "                wp = None\n",
    "            bk = action.dst\n",
    "        # toggle to_move\n",
    "        next_to_move = 'B' if to_move == 'W' else 'W'\n",
    "        return State(wk=wk, wp=wp, bk=bk, to_move=next_to_move, promoted=promoted)\n",
    "\n",
    "    def transitions(self, state: State, action: Action):\n",
    "        \"\"\"\n",
    "        Return list of (prob, next_state, reward, done) tuples for given state and action.\n",
    "        We model Black as a uniformly random opponent when it is Black's turn after our action.\n",
    "        \"\"\"\n",
    "        # Apply the immediate action\n",
    "        mid_state = self._apply_action_once(state, action)\n",
    "        # Check terminal conditions immediately after the move (e.g., promotion)\n",
    "        # Promotion chosen to terminate immediately with reward +10 for White\n",
    "        if mid_state.promoted and state.to_move == 'W':\n",
    "            # White promoted -> immediate reward\n",
    "            return [(1.0, mid_state, 10.0, True)]\n",
    "\n",
    "        # If pawn got captured by this action (shouldn't happen on white move), handle\n",
    "        if mid_state.wp is None and state.wp is not None and state.to_move == 'B':\n",
    "            # black captured pawn\n",
    "            return [(1.0, mid_state, -10.0, True)]\n",
    "\n",
    "        # If after our action it's Black to move, we must consider black responses\n",
    "        if mid_state.to_move == 'B':\n",
    "            black_actions = self.legal_actions(mid_state)\n",
    "            if not black_actions:\n",
    "                # If black has no legal actions: if in check -> checkmate; else stalemate\n",
    "                if self.in_check(mid_state, 'B'):\n",
    "                    # White delivered checkmate\n",
    "                    return [(1.0, mid_state, 10.0, True)]\n",
    "                else:\n",
    "                    return [(1.0, mid_state, 0.0, True)]\n",
    "            probs = 1.0 / len(black_actions)\n",
    "            results = []\n",
    "            for ba in black_actions:\n",
    "                ns = self._apply_action_once(mid_state, ba)\n",
    "                # if black captured pawn\n",
    "                if ns.wp is None and mid_state.wp is not None:\n",
    "                    results.append((probs, ns, -10.0, True))\n",
    "                    continue\n",
    "                # check for checkmate or stalemate when back to white\n",
    "                white_actions = self.legal_actions(ns)\n",
    "                if not white_actions:\n",
    "                    if self.in_check(ns, 'W'):\n",
    "                        # black somehow checkmates white (unlikely with only king)\n",
    "                        results.append((probs, ns, -10.0, True))\n",
    "                    else:\n",
    "                        results.append((probs, ns, 0.0, True))\n",
    "                else:\n",
    "                    results.append((probs, ns, 0.0, False))\n",
    "            return results\n",
    "        else:\n",
    "            # If it becomes White to move (e.g., black action returned immediately), just return\n",
    "            return [(1.0, mid_state, 0.0, False)]\n",
    "\n",
    "    # Transition / step (single deterministic action application)\n",
    "    def step(self, state: State, action: Action):\n",
    "        \"\"\"Apply action to state and return one sample (next_state, reward, done, info).\n",
    "        This picks one of the possible stochastic outcomes (if any) at random. For DP we will use transitions().\"\"\"\n",
    "        trans = self.transitions(state, action)\n",
    "        # sample according to probabilities\n",
    "        p = np.random.random()\n",
    "        cum = 0.0\n",
    "        for prob, ns, r, done in trans:\n",
    "            cum += prob\n",
    "            if p <= cum:\n",
    "                return ns, r, done, {}\n",
    "        # fallback\n",
    "        prob, ns, r, done = trans[-1]\n",
    "        return ns, r, done, {}\n",
    "\n",
    "    def reset(self, initial: Optional[State] = None):\n",
    "        # Default starting configuration (students should document their chosen initial state)\n",
    "        if initial is not None:\n",
    "            self.state = initial\n",
    "            self.steps = 0\n",
    "            return self.state\n",
    "        # we pick a reasonable default for 4x4 board\n",
    "        if self.N == 4:\n",
    "            wk = (3, 0)\n",
    "            wp = (2, 1)\n",
    "            bk = (0, 3)\n",
    "        else:\n",
    "            wk = (4, 0)\n",
    "            wp = (3, 1)\n",
    "            bk = (0, 4)\n",
    "        self.state = State(wk=wk, wp=wp, bk=bk, to_move='W', promoted=False)\n",
    "        self.steps = 0\n",
    "        return self.state\n",
    "\n",
    "    def render(self, state: Optional[State] = None):\n",
    "        s = state or self.state\n",
    "        board = [['.' for _ in range(self.N)] for _ in range(self.N)]\n",
    "        if s.wp is not None:\n",
    "            r, c = s.wp\n",
    "            board[r][c] = 'P' if not s.promoted else 'Q'\n",
    "        wr, wc = s.wk\n",
    "        board[wr][wc] = 'K'\n",
    "        br, bc = s.bk\n",
    "        board[br][bc] = 'k'\n",
    "        print(f\"To move: {s.to_move}  promoted: {s.promoted}\")\n",
    "        for r in range(self.N):\n",
    "            print(' '.join(board[r]))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b8921af",
   "metadata": {
    "id": "0b8921af"
   },
   "outputs": [],
   "source": [
    "# State encoding & Listing - 1 mark\n",
    "\n",
    "class StateIndexer:\n",
    "    def __init__(self, states: List[State]):\n",
    "        # Build bidirectional maps between State and index\n",
    "        self.states = list(states)\n",
    "        self.s2i: Dict[Any, int] = {s.as_tuple(): i for i, s in enumerate(self.states)}\n",
    "        self.i2s: Dict[int, State] = {i: s for i, s in enumerate(self.states)}\n",
    "\n",
    "    def _build(self):\n",
    "        # Already built in __init__\n",
    "        pass\n",
    "\n",
    "    def encode(self, state: State) -> int:\n",
    "        return self.s2i[state.as_tuple()]\n",
    "\n",
    "    def decode(self, idx: int) -> State:\n",
    "        return self.i2s[idx]\n",
    "\n",
    "# List all reachable states (BFS) from an initial state - 1 mark\n",
    "\n",
    "def list_reachable(env: MiniChessEnv, initial: State):\n",
    "    \"\"\"Breadth-first search of reachable states using all legal actions and transitions.\n",
    "    We include non-terminal mid-states as well. Because transitions can create stochastic branches\n",
    "    (black random moves), we include all resulting next-states seen.\n",
    "    \"\"\"\n",
    "    q = deque()\n",
    "    seen = set()\n",
    "    q.append(initial)\n",
    "    seen.add(initial.as_tuple())\n",
    "    results = [initial]\n",
    "    while q:\n",
    "        s = q.popleft()\n",
    "        actions = env.legal_actions(s)\n",
    "        for a in actions:\n",
    "            for prob, ns, r, done in env.transitions(s, a):\n",
    "                key = ns.as_tuple()\n",
    "                if key not in seen:\n",
    "                    seen.add(key)\n",
    "                    results.append(ns)\n",
    "                    if not done:\n",
    "                        q.append(ns)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44321269",
   "metadata": {
    "id": "44321269"
   },
   "outputs": [],
   "source": [
    "# Value Iteration / Policy Iteration - 1 mark\n",
    "\n",
    "def value_iteration(env: MiniChessEnv, states: List[State], gamma: float = 0.99, theta: float = 1e-3, max_iters: int = 10000):\n",
    "    \"\"\"Perform value iteration on the provided states.\n",
    "    Returns (V, policy, stats) where stats contains iterations, final_delta, runtime\n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    indexer = StateIndexer(states)\n",
    "    V = {s.as_tuple(): 0.0 for s in states}\n",
    "    policy: Dict[Any, Action] = {}\n",
    "\n",
    "    iteration = 0\n",
    "    while iteration < max_iters:\n",
    "        delta = 0.0\n",
    "        for s in states:\n",
    "            key = s.as_tuple()\n",
    "            actions = env.legal_actions(s)\n",
    "            if not actions:\n",
    "                # terminal-like\n",
    "                if env.in_check(s, s.to_move):\n",
    "                    v_new = -10.0 if s.to_move == 'W' else 10.0\n",
    "                else:\n",
    "                    v_new = 0.0\n",
    "                V[key] = v_new\n",
    "                continue\n",
    "            best_a_val = -1e9\n",
    "            best_a = None\n",
    "            for a in actions:\n",
    "                q_sa = 0.0\n",
    "                for prob, ns, r, done in env.transitions(s, a):\n",
    "                    if done:\n",
    "                        q_sa += prob * r\n",
    "                    else:\n",
    "                        q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                if q_sa > best_a_val:\n",
    "                    best_a_val = q_sa\n",
    "                    best_a = a\n",
    "            delta = max(delta, abs(V[key] - best_a_val))\n",
    "            V[key] = best_a_val\n",
    "            if s.to_move == 'W' and best_a is not None:\n",
    "                policy[key] = best_a\n",
    "        iteration += 1\n",
    "        if delta < theta:\n",
    "            break\n",
    "    runtime = time.time() - start\n",
    "    stats = {'iterations': iteration, 'final_delta': delta, 'runtime': runtime}\n",
    "    return V, policy, stats\n",
    "\n",
    "\n",
    "def policy_evaluation(env: MiniChessEnv, states: List[State], policy: Dict[Any, Action], gamma: float = 0.99, theta: float = 1e-3):\n",
    "    \"\"\"Evaluate a fixed policy (policy maps White states to actions).\"\"\"\n",
    "    V = {s.as_tuple(): 0.0 for s in states}\n",
    "    while True:\n",
    "        delta = 0.0\n",
    "        for s in states:\n",
    "            key = s.as_tuple()\n",
    "            actions = env.legal_actions(s)\n",
    "            if not actions:\n",
    "                if env.in_check(s, s.to_move):\n",
    "                    v_new = -10.0 if s.to_move == 'W' else 10.0\n",
    "                else:\n",
    "                    v_new = 0.0\n",
    "            else:\n",
    "                if s.to_move == 'W':\n",
    "                    a = policy.get(key)\n",
    "                    if a is None:\n",
    "                        # if no policy action, pick first\n",
    "                        a = actions[0]\n",
    "                    q_sa = 0.0\n",
    "                    for prob, ns, r, done in env.transitions(s, a):\n",
    "                        if done:\n",
    "                            q_sa += prob * r\n",
    "                        else:\n",
    "                            q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                    v_new = q_sa\n",
    "                else:\n",
    "                    # Black to move: treat as uniform random\n",
    "                    q_val = 0.0\n",
    "                    for ba in actions:\n",
    "                        # use immediate application since transitions for black may include randomness\n",
    "                        for prob, ns, r, done in env.transitions(s, ba):\n",
    "                            if done:\n",
    "                                q_val += (1.0 / len(actions)) * prob * r\n",
    "                            else:\n",
    "                                q_val += (1.0 / len(actions)) * prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "                    v_new = q_val\n",
    "            delta = max(delta, abs(V[key] - v_new))\n",
    "            V[key] = v_new\n",
    "        if delta < theta:\n",
    "            break\n",
    "    return V\n",
    "\n",
    "\n",
    "def policy_improvement(env: MiniChessEnv, states: List[State], V: Dict[Any, float], gamma: float = 0.99):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if s.to_move != 'W':\n",
    "            continue\n",
    "        actions = env.legal_actions(s)\n",
    "        if not actions:\n",
    "            continue\n",
    "        best_val = -1e9\n",
    "        best_a = None\n",
    "        for a in actions:\n",
    "            q_sa = 0.0\n",
    "            for prob, ns, r, done in env.transitions(s, a):\n",
    "                if done:\n",
    "                    q_sa += prob * r\n",
    "                else:\n",
    "                    q_sa += prob * (r + gamma * V.get(ns.as_tuple(), 0.0))\n",
    "            if q_sa > best_val:\n",
    "                best_val = q_sa\n",
    "                best_a = a\n",
    "        policy[s.as_tuple()] = best_a\n",
    "    return policy\n",
    "\n",
    "\n",
    "def policy_iteration(env: MiniChessEnv, states: List[State], gamma: float = 0.99, theta: float = 1e-3, max_iters: int = 100):\n",
    "    \"\"\"Classic policy iteration focusing on White's choices.\n",
    "    Returns V, policy, stats\n",
    "    \"\"\"\n",
    "    # initialize random policy for White states\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        if s.to_move == 'W':\n",
    "            acts = env.legal_actions(s)\n",
    "            if acts:\n",
    "                policy[s.as_tuple()] = acts[0]\n",
    "    start = time.time()\n",
    "    it = 0\n",
    "    while it < max_iters:\n",
    "        # policy evaluation\n",
    "        V = policy_evaluation(env, states, policy, gamma=gamma, theta=theta)\n",
    "        # policy improvement\n",
    "        new_policy = policy_improvement(env, states, V, gamma=gamma)\n",
    "        if new_policy == policy:\n",
    "            break\n",
    "        policy = new_policy\n",
    "        it += 1\n",
    "    runtime = time.time() - start\n",
    "    stats = {'iterations': it, 'runtime': runtime}\n",
    "    return V, policy, stats\n",
    "\n",
    "\n",
    "# Helper: simulate policy from a start state and print sequence\n",
    "\n",
    "def simulate_policy(env: MiniChessEnv, start: State, policy: Dict[Any, Action], max_steps: int = 50):\n",
    "    s = start\n",
    "    seq = [s]\n",
    "    for t in range(max_steps):\n",
    "        key = s.as_tuple()\n",
    "        if s.to_move == 'W':\n",
    "            a = policy.get(key)\n",
    "            if a is None:\n",
    "                acts = env.legal_actions(s)\n",
    "                if not acts:\n",
    "                    break\n",
    "                a = acts[0]\n",
    "            ns, r, done, _ = env.step(s, a)\n",
    "            seq.append((a, ns, r, done))\n",
    "            if done:\n",
    "                break\n",
    "            s = ns\n",
    "        else:\n",
    "            # Black random move\n",
    "            acts = env.legal_actions(s)\n",
    "            if not acts:\n",
    "                break\n",
    "            a = acts[np.random.randint(len(acts))]\n",
    "            ns, r, done, _ = env.step(s, a)\n",
    "            seq.append((a, ns, r, done))\n",
    "            if done:\n",
    "                break\n",
    "            s = ns\n",
    "    return seq\n",
    "\n",
    "# Runner to compare VI and PI and produce convergence stats and heatmaps\n",
    "\n",
    "def run_experiment(env: MiniChessEnv, initial: State):\n",
    "    states = list_reachable(env, initial)\n",
    "    print(f\"Enumerated {len(states)} reachable states\")\n",
    "\n",
    "    V_vi, pi_vi, stats_vi = value_iteration(env, states, gamma=0.99, theta=1e-3)\n",
    "    print(\"Value Iteration stats:\", stats_vi)\n",
    "\n",
    "    V_pi, pi_pi, stats_pi = policy_iteration(env, states, gamma=0.99, theta=1e-3)\n",
    "    print(\"Policy Iteration stats:\", stats_pi)\n",
    "\n",
    "    return {\n",
    "        'states': states,\n",
    "        'vi': (V_vi, pi_vi, stats_vi),\n",
    "        'pi': (V_pi, pi_pi, stats_pi),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15d4bca3",
   "metadata": {
    "id": "15d4bca3"
   },
   "outputs": [],
   "source": [
    "# Visualization - 0.5 mark\n",
    "\n",
    "def plot_value(env: MiniChessEnv, V: Dict[Any, float], fixed_wp: Pos, fixed_bk: Pos):\n",
    "    \"\"\"Fix pawn and black king positions; vary white king position and show heatmap of V(s).\n",
    "    White king positions that overlap pawn or black king are skipped.\n",
    "    \"\"\"\n",
    "    N = env.N\n",
    "    heat = np.full((N, N), np.nan)\n",
    "    for r in range(N):\n",
    "        for c in range(N):\n",
    "            wk = (r, c)\n",
    "            # skip invalid overlap\n",
    "            if wk == fixed_wp or wk == fixed_bk:\n",
    "                continue\n",
    "            s = State(wk=wk, wp=fixed_wp, bk=fixed_bk, to_move='W', promoted=False)\n",
    "            key = s.as_tuple()\n",
    "            if key in V:\n",
    "                heat[r, c] = V[key]\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    plt.title('Value heatmap for White to move (higher better)')\n",
    "    plt.imshow(heat, origin='upper', cmap='coolwarm')\n",
    "    plt.colorbar()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66125bdb",
   "metadata": {
    "id": "66125bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial state:\n",
      "To move: W  promoted: False\n",
      ". . . k\n",
      ". . . .\n",
      ". P . .\n",
      "K . . .\n",
      "\n",
      "Enumerated 993 reachable states\n",
      "Value Iteration stats: {'iterations': 5, 'final_delta': 0.0, 'runtime': 0.3464944362640381}\n",
      "Policy Iteration stats: {'iterations': 3, 'runtime': 2.0015859603881836}\n",
      "\n",
      "Examples from Value Iteration policy:\n",
      "State: State(wk=(3, 0), wp=(2, 1), bk=(0, 3), to_move='W', promoted=False) -> V=9.900, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(0, 2), to_move='W', promoted=False) -> V=9.875, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(1, 2), to_move='W', promoted=False) -> V=9.884, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(2, 0), wp=(2, 1), bk=(1, 3), to_move='W', promoted=False) -> V=9.900, best action: P (2, 1)->(1, 1)\n",
      "State: State(wk=(3, 1), wp=(2, 1), bk=(0, 2), to_move='W', promoted=False) -> V=9.801, best action: K (3, 1)->(2, 2)\n",
      "State: State(wk=(3, 1), wp=(2, 1), bk=(1, 2), to_move='W', promoted=False) -> V=9.884, best action: P (2, 1)->(1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulated rollout (Value Iteration policy):\n",
      "To move: W  promoted: False\n",
      ". . . k\n",
      ". . . .\n",
      ". P . .\n",
      "K . . .\n",
      "\n",
      "Action: P (2, 1)->(1, 1)  reward=0.0 done=False\n",
      "To move: W  promoted: False\n",
      ". . k .\n",
      ". P . .\n",
      ". . . .\n",
      "K . . .\n",
      "\n",
      "Action: P (1, 1)->(0, 1)  reward=10.0 done=True\n",
      "To move: B  promoted: True\n",
      ". Q k .\n",
      ". . . .\n",
      ". . . .\n",
      "K . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Main Usage - 1 mark\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create environment (default 4x4 board)\n",
    "    env = MiniChessEnv(board_size=4)\n",
    "\n",
    "    # Documenting choices:\n",
    "    # - Board chosen: 4x4 (default). Pawn moves upwards (decreasing row index).\n",
    "    # - Promotion terminates immediately with reward +10.\n",
    "    # - Black acts as a uniformly random opponent for DP modeling.\n",
    "\n",
    "    # Reset to default initial state\n",
    "    initial = env.reset()\n",
    "    print(\"Initial state:\")\n",
    "    env.render(initial)\n",
    "\n",
    "    # Run full experiment (enumerate states, run VI and PI)\n",
    "    results = run_experiment(env, initial)\n",
    "    states = results['states']\n",
    "    V_vi, pi_vi, stats_vi = results['vi']\n",
    "    V_pi, pi_pi, stats_pi = results['pi']\n",
    "\n",
    "    # Show a few example state values and chosen actions (Value Iteration policy)\n",
    "    print('\\nExamples from Value Iteration policy:')\n",
    "    cnt = 0\n",
    "    for s in states:\n",
    "        key = s.as_tuple()\n",
    "        if key in pi_vi and s.to_move == 'W':\n",
    "            a = pi_vi[key]\n",
    "            print(f\"State: {s} -> V={V_vi[key]:.3f}, best action: {a.piece} {a.src}->{a.dst}\")\n",
    "            cnt += 1\n",
    "            if cnt >= 6:\n",
    "                break\n",
    "\n",
    "    # Visualize value heatmap fixing pawn and black king\n",
    "    if initial.wp is not None:\n",
    "        plot_value(env, V_vi, fixed_wp=initial.wp, fixed_bk=initial.bk)\n",
    "\n",
    "    # Simulate a policy rollout from the initial state\n",
    "    print('\\nSimulated rollout (Value Iteration policy):')\n",
    "    seq = simulate_policy(env, initial, pi_vi, max_steps=50)\n",
    "    for item in seq:\n",
    "        if isinstance(item, State):\n",
    "            env.render(item)\n",
    "        else:\n",
    "            a, ns, r, done = item\n",
    "            print(f\"Action: {a.piece} {a.src}->{a.dst}  reward={r} done={done}\")\n",
    "            env.render(ns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9120f8",
   "metadata": {},
   "source": [
    "# Result Discussion and descriptive answers, conclusion - 1 mark\n",
    "\n",
    "**Summary of results (example run on 4×4 board)**\n",
    "\n",
    "- Reachable states enumerated from the chosen initial state: 993 (BFS over legal moves and stochastic black responses).\n",
    "- Value Iteration: converged in 5 iterations (final max-value change ≈ 0.0); runtime ≈ 0.32 s.\n",
    "- Policy Iteration: converged in 3 policy-improvement steps; runtime ≈ 2.06 s.\n",
    "\n",
    "**Deliverable checklist & descriptive answers**\n",
    "\n",
    "- Custom environment: `MiniChessEnv` implements `reset()`, `step()` (deterministic sample via `transitions()`), and `render()`. It enforces legal moves, pawn captures, promotion (chosen to terminate immediately), kings-adjacency rule, and basic check/checkmate/stalemate detection.\n",
    "\n",
    "- Initial configuration rule used: (ID last-digit rule) this run used the 0–4 branch — WK and BK in opposite corners, WP on the rank closest to White. This choice favors a straightforward promotion race and keeps states interpretable.\n",
    "\n",
    "- DP solutions implemented: `value_iteration()` and `policy_iteration()` producing `V*(s)` and a greedy policy `π*(s)` for White. Stopping criterion: max change < θ (default 1e-3).\n",
    "\n",
    "- Convergence and runtime: VI converged quickly (few iterations) on this small MDP; PI required fewer improvement rounds but more per-iteration work — both are practical for 4×4.\n",
    "\n",
    "- Visual & qualitative analysis: heatmaps (fixed pawn + fixed BK, varying WK) show higher values when the White king is near the pawn and far from the Black king. Policies tend to advance the pawn when safe and use the king to block/capture threats.\n",
    "\n",
    "**Descriptive answers to analysis questions**\n",
    "\n",
    "1. How does state design affect convergence?\n",
    "- Compact state encoding and early terminal handling (promotion-as-termination) reduce the enumerated state-space and speed up backups. Adding flags (promoted, move counts) increases state count and slows DP.\n",
    "\n",
    "2. Reward shaping effects?\n",
    "- Strong terminal rewards (+10 for promotion/checkmate, −10 for pawn capture) create clear value gradients and fast convergence. Smaller rewards or sparse signals would need more iterations and make policies less decisive.\n",
    "\n",
    "3. Why use random Black opponent in this MDP?\n",
    "- Modeling Black as uniform-random converts the game into an MDP (stochastic transitions) suitable for DP; an adversarial Black requires minimax or robust formulations.\n",
    "\n",
    "**Limitations & suggestions**\n",
    "\n",
    "- Promotion-as-termination simplifies analysis but omits post-promotion play; to study full endgames, implement Queen moves and continue episodes.\n",
    "- Scaling to larger boards or extra pieces quickly explodes state-space; consider function approximation or sample-based RL for larger problems.\n",
    "\n",
    "**Conclusion (1 mark)**\n",
    "\n",
    "This notebook implements a complete MiniChess MDP and applies tabular dynamic programming to obtain high-quality policies for White on tiny boards. Results show that advancing the pawn toward promotion (when supported by the king) is the dominant strategy. While DP works well for the reduced game, full chess requires approximate, sample-based, or search-driven methods due to the curse of dimensionality.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
